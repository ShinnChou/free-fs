# 分片上传、断点续传完整方案

## 一、架构设计

### 1.1 核心流程

```
前端选择文件
    ↓
计算文件MD5 → 初始化上传（同步）→ 返回taskId
    ↓
WebSocket订阅进度(taskId)
    ↓
查询已上传分片 → 获取断点信息
    ↓
并发上传分片（异步）→ WebSocket推送进度
    ↓
所有分片完成 → 服务端自动合并
    ↓
推送complete → 上传完成
```

### 1.2 并发控制策略

**前端控制并发（推荐）**：
- 批量上传5个文件
- 每个文件3-5个分片并发
- 总并发数：15-25个HTTP请求

**服务端配置**：
```java
// 线程池配置
CorePoolSize: 15      // 核心线程数
MaxPoolSize: 20       // 最大线程数
QueueCapacity: 100    // 队列容量
```

## 二、后端实现

### 2.1 接口清单

| 接口 | 方法 | 说明 | 执行方式 |
|------|------|------|----------|
| `/apis/transfer/init` | POST | 初始化上传 | **同步** |
| `/apis/transfer/chunk` | POST | 上传分片 | **异步** |
| `/apis/transfer/chunks/{taskId}` | GET | 查询已上传分片 | 同步 |
| `/ws/upload?userId={userId}` | WS | WebSocket连接 | - |

### 2.2 数据库表

#### file_upload_task (上传任务表)
```sql
- id: 主键
- task_id: 任务ID（唯一）
- user_id: 用户ID
- file_name: 文件名
- file_size: 文件大小
- file_md5: 文件MD5
- total_chunks: 总分片数
- uploaded_chunks: 已上传分片数（原子递增）
- chunk_size: 分片大小
- status: 状态
- start_time: 开始时间
```

#### file_upload_chunk (分片表)
```sql
- id: 主键
- task_id: 任务ID
- chunk_index: 分片索引
- chunk_md5: 分片MD5
- chunk_size: 分片大小
- status: 状态
- upload_time: 上传时间
```

### 2.3 核心配置

#### AsyncConfig.java
```java
@Configuration
@EnableAsync
public class AsyncConfig {
    @Bean("uploadTaskExecutor")
    public ThreadPoolTaskExecutor uploadTaskExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(15);          // 支持15个并发
        executor.setMaxPoolSize(20);           // 最大20个
        executor.setQueueCapacity(100);
        executor.setThreadNamePrefix("upload-");
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        executor.initialize();
        return executor;
    }
}
```

### 2.4 关键逻辑

#### 初始化上传（同步）
```java
public String initUpload(InitUploadCmd cmd) {
    // 1. 检查秒传
    FileInfo existFile = checkSecondUpload(cmd.getFileMd5(), ...);
    if (existFile != null) {
        return "INSTANT:" + existFile.getId();
    }
    
    // 2. 调用存储插件初始化（创建临时目录等）
    String uploadId = storageService.initiateMultipartUpload(objectKey, mimeType);
    
    // 3. 创建上传任务（保存到数据库）
    createUploadTask(uploadId, ...);
    
    // 4. 返回taskId
    return uploadId;
}
```

#### 上传分片（异步）
```java
@Async("uploadTaskExecutor")
public void uploadChunkAsync(byte[] fileBytes, UploadChunkCmd cmd) {
    // 1. MD5校验
    String actualMd5 = DigestUtils.md5DigestAsHex(fileBytes);
    
    // 2. 检查分片是否已存在（断点续传）
    FileUploadChunk existChunk = ...;
    if (existChunk != null && completed) {
        pushProgress(...);  // 推送当前进度
        return;
    }
    
    // 3. 上传分片到存储
    String etag = storageService.uploadPart(...);
    
    // 4. 保存分片记录
    saveChunkRecord(...);
    
    // 5. 原子递增计数
    fileUploadTaskMapper.incrementUploadedChunks(taskId);
    
    // 6. 推送进度
    pushProgress(...);
    
    // 7. 检查是否全部完成 → 自动合并
    if (allCompleted) {
        autoMergeChunks(taskId);
    }
}
```

#### 自动合并（异步）
```java
private void autoMergeChunks(String taskId) {
    CompletableFuture.runAsync(() -> {
        FileInfo fileInfo = mergeChunks(taskId);
        pushComplete(taskId, fileInfo);  // 推送完成消息
    }, uploadTaskExecutor);
}
```

#### 进度计算（精确统计）
```java
private void pushProgress(FileUploadTask task) {
    // 从数据库精确统计已上传分片
    List<FileUploadChunk> completedChunks = ...;
    
    int actualUploadedChunks = completedChunks.size();
    long uploadedSize = completedChunks.stream()
        .mapToLong(FileUploadChunk::getChunkSize)
        .sum();
    
    // 计算进度百分比
    double progress = (double) actualUploadedChunks / totalChunks * 100;
    
    // 计算速度和剩余时间
    long speed = uploadedSize / elapsedSeconds;
    long remainTime = remainingBytes / speed;
    
    // 推送
    uploadWebSocketHandler.pushProgress(taskId, progress);
}
```

### 2.5 WebSocket 消息类型

```java
public enum UploadMessageType {
    progress,     // 进度更新
    complete,     // 上传完成（文件合并完成）
    error,        // 错误
    success,      // 成功消息
    pong          // 心跳响应
}
```

### 2.6 进度消息格式

```json
{
  "type": "progress",
  "taskId": "xxx",
  "data": {
    "uploadedChunks": 10,
    "totalChunks": 37,
    "uploadedSize": 10485760,
    "totalSize": 38022942,
    "progress": 27.03,
    "speed": 1048576,      // 字节/秒
    "remainTime": 26       // 剩余秒数
  },
  "timestamp": 1699999999999
}
```

## 三、前端实现

### 3.1 核心代码结构

```javascript
class FileUploader {
  constructor(userId) {
    this.userId = userId;
    this.ws = null;
    this.uploadQueue = [];  // 上传队列
    this.maxConcurrentFiles = 5;  // 最多5个文件同时上传
    this.maxConcurrentChunksPerFile = 3;  // 每个文件3个分片并发
  }
  
  // 批量上传
  async uploadFiles(files) {
    for (const file of files) {
      this.addToQueue(file);
    }
    this.processQueue();
  }
  
  // 上传单个文件
  async uploadFile(file) {
    // 1. 计算MD5
    const fileMd5 = await this.calculateMD5(file);
    
    // 2. 初始化上传（同步等待）
    const result = await this.initUpload(file, fileMd5);
    
    // 3. 检查秒传
    if (result.startsWith('INSTANT:')) {
      const fileId = result.substring(8);
      console.log('秒传成功:', fileId);
      return;
    }
    
    const taskId = result;
    
    // 4. 订阅WebSocket
    this.subscribeTask(taskId);
    
    // 5. 查询已上传分片（断点续传）
    const uploadedChunks = await this.getUploadedChunks(taskId);
    
    // 6. 计算分片
    const totalChunks = Math.ceil(file.size / CHUNK_SIZE);
    const chunks = [];
    for (let i = 0; i < totalChunks; i++) {
      if (!uploadedChunks.includes(i)) {
        chunks.push(i);
      }
    }
    
    // 7. 并发上传分片（每个文件3个并发）
    await this.uploadChunksWithConcurrency(file, taskId, chunks, 3);
    
    // 8. 等待服务端自动合并完成（通过WebSocket通知）
  }
  
  // 并发上传分片
  async uploadChunksWithConcurrency(file, taskId, chunkIndexes, concurrency) {
    const queue = [...chunkIndexes];
    const workers = [];
    
    for (let i = 0; i < concurrency; i++) {
      workers.push(this.uploadWorker(file, taskId, queue));
    }
    
    await Promise.all(workers);
  }
  
  // 上传工作线程
  async uploadWorker(file, taskId, queue) {
    while (queue.length > 0) {
      const chunkIndex = queue.shift();
      if (chunkIndex === undefined) break;
      
      const start = chunkIndex * CHUNK_SIZE;
      const end = Math.min(start + CHUNK_SIZE, file.size);
      const chunk = file.slice(start, end);
      
      // 计算分片MD5
      const chunkMd5 = await this.calculateMD5(chunk);
      
      // 上传分片（HTTP立即返回，服务端异步处理）
      await this.uploadChunk(taskId, chunkIndex, chunk, chunkMd5);
    }
  }
  
  // WebSocket消息处理
  handleWebSocketMessage(message) {
    switch (message.type) {
      case 'progress':
        this.updateProgress(message.taskId, message.data);
        break;
      case 'complete':
        this.onUploadComplete(message.taskId, message.data);
        break;
      case 'error':
        this.onUploadError(message.taskId, message.message);
        break;
    }
  }
}
```

### 3.2 批量上传队列管理

```javascript
class UploadQueue {
  constructor(maxConcurrent = 5) {
    this.maxConcurrent = maxConcurrent;
    this.queue = [];
    this.running = 0;
  }
  
  add(file) {
    return new Promise((resolve, reject) => {
      this.queue.push({ file, resolve, reject });
      this.process();
    });
  }
  
  async process() {
    while (this.running < this.maxConcurrent && this.queue.length > 0) {
      const { file, resolve, reject } = this.queue.shift();
      this.running++;
      
      try {
        await uploader.uploadFile(file);
        resolve();
      } catch (error) {
        reject(error);
      } finally {
        this.running--;
        this.process();
      }
    }
  }
}
```

## 四、断点续传流程

### 4.1 暂停上传
```javascript
pauseUpload(taskId) {
  // 1. 停止分片上传循环
  this.stopUploadWorkers(taskId);
  
  // 2. 取消WebSocket订阅
  this.ws.send(JSON.stringify({
    action: 'unsubscribe',
    taskId: taskId
  }));
  
  // 3. 保存断点信息到本地
  localStorage.setItem(`upload_${taskId}`, JSON.stringify({
    taskId,
    fileName,
    fileSize,
    pausedAt: Date.now()
  }));
}
```

### 4.2 继续上传
```javascript
async resumeUpload(taskId, file) {
  // 1. 订阅WebSocket
  this.subscribeTask(taskId);
  
  // 2. 查询已上传分片
  const uploadedChunks = await this.getUploadedChunks(taskId);
  
  // 3. 计算剩余分片
  const totalChunks = Math.ceil(file.size / CHUNK_SIZE);
  const remainingChunks = [];
  for (let i = 0; i < totalChunks; i++) {
    if (!uploadedChunks.includes(i)) {
      remainingChunks.push(i);
    }
  }
  
  // 4. 继续上传剩余分片
  await this.uploadChunksWithConcurrency(file, taskId, remainingChunks, 3);
}
```

## 五、关键优化点

### 5.1 并发控制
- **前端控制**：每个文件3个分片并发
- **服务端配置**：线程池15-20个线程
- **避免混乱**：前端控制确保文件均匀推进

### 5.2 进度准确性
- 使用**原子递增**更新计数：`incrementUploadedChunks()`
- 使用**数据库精确统计**：查询已完成的分片
- 避免并发计数丢失问题

### 5.3 容错机制
- **分片MD5校验**：防止数据损坏
- **断点续传支持**：已上传的分片跳过
- **错误重试**：前端可实现重试逻辑

### 5.4 性能优化
- **MultipartFile立即读取**：避免临时文件被清理
- **异步处理**：分片上传异步，HTTP立即返回
- **自动合并**：最后一个分片完成后自动触发

## 六、测试场景

1. **单文件上传** - 验证基本流程
2. **批量上传(5个文件)** - 验证并发控制
3. **大文件上传(>100MB)** - 验证分片逻辑
4. **断点续传** - 暂停后继续上传
5. **秒传** - MD5匹配直接返回
6. **网络异常** - 部分分片失败重试
7. **并发计数** - 多个分片同时上传计数准确

## 七、常见问题

### Q1: 为什么初始化是同步的？
A: 初始化需要创建临时目录等环境准备工作，必须完成后才能开始上传分片。

### Q2: 为什么分片上传是异步的？
A: 分片上传耗时长，异步处理可以立即返回HTTP响应，提升用户体验。

### Q3: 如何保证5个文件同时上传？
A: 前端控制并发，每个文件控制自己的分片上传节奏，服务端线程池足够大即可。

### Q4: 进度为什么会跳？
A: 异步处理时，多个分片同时完成会导致进度跳跃，这是正常现象。

### Q5: 如何避免并发计数错误？
A: 使用SQL原子递增操作：`UPDATE SET uploaded_chunks = uploaded_chunks + 1`

## 八、总结

这个方案的核心特点：

1. ✅ **初始化同步** - 确保环境准备完成
2. ✅ **分片异步** - 提升响应速度
3. ✅ **自动合并** - 无需前端调用
4. ✅ **精确进度** - 数据库实时统计
5. ✅ **批量支持** - 5个文件同时上传
6. ✅ **断点续传** - 查询已上传分片继续
7. ✅ **WebSocket推送** - 实时进度反馈

